package com.smarthire.xander.POSTest;

import com.smarthire.xander.classes.GrammarChecker;
import com.smarthire.xander.classes.SentencePatternAnalyzer;

import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.InputStreamReader;
import java.io.OutputStreamWriter;
import java.io.PrintWriter;
import java.util.List;
import java.util.LinkedList;
import java.util.StringTokenizer;

import edu.stanford.nlp.ling.Sentence;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.process.DocumentPreprocessor;
import edu.stanford.nlp.process.PTBTokenizer;
import edu.stanford.nlp.process.TokenizerFactory;
import edu.stanford.nlp.tagger.maxent.MaxentTagger;

/** This demo shows user-provided sentences (i.e., {@code List<HasWord>})
 *  being tagged by the tagger. The sentences are generated by direct use
 *  of the DocumentPreprocessor class.
 *
 *  @author Zander Lumapac
 */
class POSTagClassifier {

  private POSTagClassifier() {}

  private static LinkedList<List<HasWord>> listOfSentences;
  private static LinkedList<String> listOfTaggedWords;
  
  public static void main(String[] args) throws Exception {
    String arg1 = "./src/com/smarthire/zander/POSModels/english-left3words-distsim.tagger";
    String text = "./src/com/zander/POSTestFile/1";
   // String text = "./src/com/zander/POSTestFile/sample-input.txt";
    MaxentTagger tagger = new MaxentTagger(arg1);
    
    
    TokenizerFactory<CoreLabel> ptbTokenizerFactory = PTBTokenizer.factory(new CoreLabelTokenFactory(),
									   "untokenizable=noneKeep");
    BufferedReader r = new BufferedReader(new InputStreamReader(new FileInputStream(text), "utf-8"));
    
    PrintWriter pw = new PrintWriter(new OutputStreamWriter(System.out, "utf-8"));
    DocumentPreprocessor documentPreprocessor = new DocumentPreprocessor(r);
    documentPreprocessor.setTokenizerFactory(ptbTokenizerFactory);
//  
    
    listOfSentences = new LinkedList<>();
    listOfTaggedWords = new LinkedList<>();
     for (List<HasWord> sentence : documentPreprocessor) {
        System.out.println("sentence = "+sentence.toString());
        listOfSentences.add(sentence);
        List<TaggedWord> tSentence = tagger.tagSentence(sentence);
         System.out.println("ts "+tSentence.toString());
           pw.println(Sentence.listToString(tSentence, false));
        listOfTaggedWords.add(tSentence.toString().substring(1, tSentence.toString().length()-1));
      
    }
     

    // print the adjectives in one more sentence. This shows how to get at words and tags in a tagged sentence.
//    List<HasWord> sent = Sentence.toWordList("The", "slimy", "slug", "crawled", "over", "the", "long", ",", "green", "grass", ".");
//   
//    List<TaggedWord> taggedSent = tagger.tagSentence(sent);
//    
//    System.out.println("print adjectives");
//    for (TaggedWord tw : taggedSent) {
//      if (tw.tag().startsWith("JJ")) {
//        pw.println(tw.word());
//      }
//    }
//    
     
      System.out.println("listOftagg");
     for(String k: listOfTaggedWords){
         System.out.println(""+k);
     }
      System.out.println("tag nos "+listOfTaggedWords.toString());
      
    
    identifyPattern();
    
    
    
    pw.close();
  }
  
  private static void identifyPattern(){
      LinkedList<LinkedList<String>> sentenceTags = new LinkedList<>();
      System.out.println("ltw = "+listOfTaggedWords.size());
      int c = 0;
      for(String s : listOfTaggedWords){
          System.out.println(" "+s);
        LinkedList<String> listOfTags = new LinkedList<>();
        StringTokenizer st = new StringTokenizer(s, ",");
        String compound;
        while(st.hasMoreElements()){
            compound = st.nextToken();
            System.out.println(""+c++);
            StringTokenizer str = new StringTokenizer(compound, "/");
           // System.out.println("count = "+str.countTokens());
            if(str.countTokens() < 2){
                System.out.println("reading , ... disregarded");
            }else{
                String word = str.nextToken();
          //      System.out.println("word = "+word);
                if(str.hasMoreTokens()){
                   // System.out.println("tag = "+str.nextToken());
                  listOfTags.add(str.nextToken());
                }
            }
        }
        for(String sq: listOfTags){
            System.out.print("\t"+sq);
        }
        sentenceTags.add(listOfTags);
        GrammarChecker gc = new GrammarChecker();
        gc.isGrammaticallyCorrect(listOfTags);
      }
      
//      for(LinkedList<String> k: sentenceTags){
//        SentencePatternAnalyzer spa = new SentencePatternAnalyzer();
//        spa.analyze(k);
//      }
  }

}
